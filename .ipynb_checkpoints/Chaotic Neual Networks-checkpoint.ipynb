{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66697720-26d7-4601-94fb-7826b096b3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.integrate import solve_ivp\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7dbb0717-cb88-44d4-a842-a5ace77be43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChaoticLayer(nn.Module):\n",
    "    def __init__(self,iterations=1000,dt=0.01):\n",
    "        super(ChaoticLayer,self).__init__()\n",
    "        self.iterations = iterations\n",
    "        self.dt = dt\n",
    "    def forward(self,x):\n",
    "        def lorenz(t,state, beta = 8/3, rho = 28, sigma = 10):\n",
    "            x,y,z = state\n",
    "            dx = sigma*(y-x)\n",
    "            dy = rho*x-y-x*z\n",
    "            dz = -beta*z + x*y\n",
    "            return [dx,dy,dz]\n",
    "        trajectories = []\n",
    "        for sample in x:\n",
    "            x1 = sample[0].item()\n",
    "            x2 = sample[1].item()\n",
    "            initial_state = [x1,x2,np.sqrt(x1**2+x2**2)]\n",
    "            times_at_which_func_eval = np.linspace(0,self.iterations*self.dt,self.iterations)\n",
    "            trajectory = solve_ivp(fun = lorenz,\n",
    "                                  y0 = initial_state,\n",
    "                                  t_span = [0,self.iterations*self.dt],\n",
    "                                  t_eval = times_at_which_func_eval,\n",
    "                                  )\n",
    "            '''\n",
    "            We only take the second half of the trajectory since the Lorenz attractor needs some \n",
    "            time to stabilise before exhibiting chaotic behaviour\n",
    "            '''\n",
    "            halfway_point = trajectory.y.shape[1] // 2\n",
    "            x = trajectory.y[0,halfway_point:]\n",
    "            y = trajectory.y[1,halfway_point:]\n",
    "            z = trajectory.y[2,halfway_point:]\n",
    "            # we take the summary statistics of all 3-D points to get the features we are gonna use for our prediction\n",
    "            x_mean = np.mean(x)\n",
    "            y_mean = np.mean(y)\n",
    "            z_mean = np.mean(z)\n",
    "            z_std_dev = np.std(z)\n",
    "            y_std_dev = np.std(y)\n",
    "            x_std_dev = np.std(x)\n",
    "            corr = np.mean(np.sqrt(x**2+y**2+z**2))\n",
    "            features_of_trajectory = [x_mean,y_mean,z_mean,x_std_dev,y_std_dev,z_std_dev,corr]\n",
    "            trajectories.append(features_of_trajectory)\n",
    "        return torch.tensor(trajectories,dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0fa3c983-2cc2-4e3f-8a6f-1ef524712c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MainNet,self).__init__()\n",
    "        self.input_fc = nn.Linear(2,16)\n",
    "        self.input_bn = nn.BatchNorm1d(16)\n",
    "\n",
    "        self.chaotic_layer = ChaoticLayer(iterations=1000,dt=0.01)\n",
    "        \n",
    "        self.hidden = nn.Linear(16+7,16)\n",
    "        self.hidden_bn = nn.BatchNorm1d(16)\n",
    "\n",
    "        self.output = nn.Linear(16,1)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self,x):\n",
    "        x_hidden = self.input_fc(x)\n",
    "        x_hidden = self.input_bn(self.relu(x_hidden))\n",
    "        x_chaotic = self.chaotic_layer(x)\n",
    "        x_combined = torch.cat([x_hidden,x_chaotic],dim=1)\n",
    "        x_combined = self.hidden(x_combined)\n",
    "        x_combined = self.hidden_bn(x_combined)\n",
    "        x_combined = self.relu(x_combined)\n",
    "        x_out = self.output(x_combined)\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2d20c649-f53e-440c-8202-64706c1d1929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeLCM(x,y):\n",
    "    x,y = int(x),int(y)\n",
    "    return abs(x*y)//np.gcd(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "61308b4e-87fb-4bdc-a16f-cdd2ff19f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "826e2cc0-f593-4274-a802-aba22a68decf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randint(1,50,(200,2)).float()\n",
    "target = torch.tensor([computeLCM(a,b) for a,b in inputs.numpy()],dtype=torch.float32).unsqueeze(1)\n",
    "input_scaler = MinMaxScaler()\n",
    "target_scaler = MinMaxScaler()\n",
    "inputs = torch.tensor(input_scaler.fit_transform(inputs),dtype=torch.float32)\n",
    "target = torch.tensor(target_scaler.fit_transform(target),dtype=torch.float32)\n",
    "\n",
    "train_size = 160\n",
    "input_train,input_test = inputs[:train_size],inputs[train_size:]\n",
    "target_train,target_test = target[:train_size],target[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "00e0be20-809b-4f58-a16c-4d6d1cc36c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b47cea63-9785-47ac-9b20-b66bbe707cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2299\n",
      "Epoch 50, Loss: 0.0222\n",
      "Epoch 100, Loss: 0.0119\n",
      "Epoch 150, Loss: 0.0109\n",
      "Epoch 200, Loss: 0.0105\n",
      "Epoch 250, Loss: 0.0102\n",
      "Epoch 300, Loss: 0.0098\n",
      "Epoch 350, Loss: 0.0094\n",
      "Epoch 400, Loss: 0.0091\n",
      "Epoch 450, Loss: 0.0088\n",
      "Epoch 500, Loss: 0.0085\n",
      "Epoch 550, Loss: 0.0083\n",
      "Epoch 600, Loss: 0.0080\n",
      "Epoch 650, Loss: 0.0076\n",
      "Epoch 700, Loss: 0.0072\n",
      "Epoch 750, Loss: 0.0070\n",
      "Epoch 800, Loss: 0.0067\n",
      "Epoch 850, Loss: 0.0066\n",
      "Epoch 900, Loss: 0.0064\n",
      "Epoch 950, Loss: 0.0062\n"
     ]
    }
   ],
   "source": [
    "model = MainNet()\n",
    "optimiser = RAdam(model.parameters(),lr=0.005)\n",
    "criterion = nn.MSELoss()\n",
    "for epoch in range(1000):\n",
    "    model.train()\n",
    "    optimiser.zero_grad()\n",
    "    outputs = model(input_train)\n",
    "    loss = criterion(outputs,target_train)\n",
    "\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    if epoch % 50 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b1a7b5e3-e445-493b-ac93-e749fd7dc420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0513\n",
      "\n",
      "Sample Predictions (Original Scale):\n",
      "Input: [0.6041667 0.9791667], Predicted LCM: 1190.36, True LCM: 239.99998474121094\n",
      "Input: [0.7291667  0.16666667], Predicted LCM: 201.68, True LCM: 36.0\n",
      "Input: [0.0625     0.41666666], Predicted LCM: -224.53, True LCM: 84.00000762939453\n",
      "Input: [0.6458333 0.7083333], Predicted LCM: 1189.26, True LCM: 1120.0\n",
      "Input: [0.75       0.41666666], Predicted LCM: 916.66, True LCM: 777.0\n",
      "Input: [0.9375    0.9166667], Predicted LCM: 2663.95, True LCM: 2070.0\n",
      "Input: [0.39583334 1.        ], Predicted LCM: 1091.99, True LCM: 980.0\n",
      "Input: [0.39583334 0.0625    ], Predicted LCM: 94.05, True LCM: 20.0\n",
      "Input: [0.7291667  0.14583333], Predicted LCM: 90.94, True LCM: 72.0\n",
      "Input: [0.75 0.5 ], Predicted LCM: 898.16, True LCM: 925.0\n",
      "\n",
      "Mean Absolute Percentage Error (MAPE): 348.54%\n"
     ]
    }
   ],
   "source": [
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(input_test)\n",
    "        test_loss = criterion(test_outputs, target_test)\n",
    "        print(f\"Test Loss: {test_loss.item():.4f}\")\n",
    "\n",
    "        # Inverse transform\n",
    "        test_outputs_orig = target_scaler.inverse_transform(test_outputs.numpy())\n",
    "        test_lcm_targets_orig = target_scaler.inverse_transform(target_test.numpy())\n",
    "\n",
    "        print(\"\\nSample Predictions (Original Scale):\")\n",
    "        for i in range(min(10, len(input_test))):\n",
    "            print(\n",
    "                f\"Input: {input_test[i].numpy()}, \"\n",
    "                f\"Predicted LCM: {test_outputs_orig[i][0]:.2f}, \"\n",
    "                f\"True LCM: {test_lcm_targets_orig[i][0]}\"\n",
    "            )\n",
    "\n",
    "        # MAPE\n",
    "        mape = torch.mean(\n",
    "            torch.abs(\n",
    "                (torch.tensor(test_lcm_targets_orig) - torch.tensor(test_outputs_orig))\n",
    "                / torch.tensor(test_lcm_targets_orig)\n",
    "            )\n",
    "        ) * 100\n",
    "        print(f\"\\nMean Absolute Percentage Error (MAPE): {mape.item():.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
