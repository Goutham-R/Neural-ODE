{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71a5d940-d79d-44d0-9892-9a97938a21e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.example_libraries import stax\n",
    "from jax.example_libraries.stax import Dense, Relu\n",
    "import diffrax\n",
    "import tensorflow_datasets as tfds\n",
    "from jax.example_libraries import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba2ac4ea-fbc6-4cdf-b13d-957899a3114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c935c26-86d4-4706-be8c-33a98d2bc779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# Model Definition\n",
    "# ---------------------\n",
    "\n",
    "# Define network components with stax.\n",
    "hidden_dim = 64\n",
    "num_classes = 10\n",
    "\n",
    "# fc_in: projects input (784-dim) to hidden_dim.\n",
    "fc_in_init, fc_in_apply = stax.serial(\n",
    "    Dense(hidden_dim),\n",
    "    Relu\n",
    ")\n",
    "\n",
    "# ode_net: defines the ODE dynamics on the hidden state.\n",
    "# It takes a hidden state and returns its time derivative.\n",
    "ode_net_init, ode_net_apply = stax.serial(\n",
    "    Dense(50),\n",
    "    Relu,\n",
    "    Dense(hidden_dim)\n",
    ")\n",
    "\n",
    "# fc_out: maps the final hidden state to logits.\n",
    "fc_out_init, fc_out_apply = stax.serial(\n",
    "    Dense(num_classes)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af0ae987-fce4-4622-915e-adb945cb4650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The full model function. Given parameters and an input x,\n",
    "# it applies fc_in, evolves the hidden state using diffrax, then applies fc_out.\n",
    "def apply_model(params, x):\n",
    "    params_fc_in, params_ode, params_fc_out = params\n",
    "    # Project input using fc_in.\n",
    "    h0 = fc_in_apply(params_fc_in, x)\n",
    "    \n",
    "    # Define the ODE function.\n",
    "    def ode_fun(t, y, args):\n",
    "        # Here we ignore t (you could add time-dependence if desired).\n",
    "        return ode_net_apply(params_ode, y)\n",
    "    \n",
    "    term = diffrax.ODETerm(ode_fun)\n",
    "    # Solve the ODE from t=0 to t=1.\n",
    "    sol = diffrax.diffeqsolve(\n",
    "        term,\n",
    "        solver=diffrax.Dopri5(),\n",
    "        t0=0.0,\n",
    "        t1=1.0,\n",
    "        dt0=0.1,\n",
    "        y0=h0,\n",
    "        saveat=diffrax.SaveAt(ts=jnp.array([1.0]))\n",
    "    )\n",
    "    h_T = sol.ys[0]  # final hidden state at t = 1.0\n",
    "    logits = fc_out_apply(params_fc_out, h_T)\n",
    "    return logits\n",
    "\n",
    "# Cross-entropy loss.\n",
    "def loss_fn(params, x, y):\n",
    "    logits = apply_model(params, x)\n",
    "    log_probs = jax.nn.log_softmax(logits)\n",
    "    one_hot = jax.nn.one_hot(y, num_classes)\n",
    "    return -jnp.mean(jnp.sum(one_hot * log_probs, axis=-1))\n",
    "\n",
    "# Accuracy function.\n",
    "def accuracy_fn(params, x, y):\n",
    "    logits = apply_model(params, x)\n",
    "    predictions = jnp.argmax(logits, axis=-1)\n",
    "    return jnp.mean(predictions == y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c45299d-f32b-4360-bbf4-80cfd0fec052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 12:05:47.503014: W external/local_tsl/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /Users/goutham/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86892adb85e4fd98080e2a9aa75d79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to /Users/goutham/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "# Data Loading & Preprocessing\n",
    "# ---------------------\n",
    "\n",
    "# Load MNIST via tensorflow_datasets.\n",
    "ds_builder = tfds.builder(\"mnist\")\n",
    "ds_builder.download_and_prepare()\n",
    "train_ds = tfds.as_numpy(ds_builder.as_dataset(split=\"train\", batch_size=-1))\n",
    "test_ds  = tfds.as_numpy(ds_builder.as_dataset(split=\"test\", batch_size=-1))\n",
    "\n",
    "# Preprocess: flatten images and normalize.\n",
    "x_train = train_ds[\"image\"].reshape(-1, 28*28) / 255.0\n",
    "y_train = train_ds[\"label\"]\n",
    "x_test  = test_ds[\"image\"].reshape(-1, 28*28) / 255.0\n",
    "y_test  = test_ds[\"label\"]\n",
    "\n",
    "# Utility: create minibatches.\n",
    "def get_batches(x, y, batch_size, key):\n",
    "    n = x.shape[0]\n",
    "    perm = jax.random.permutation(key, n)\n",
    "    for i in range(0, n, batch_size):\n",
    "        batch_idx = perm[i:i+batch_size]\n",
    "        yield x[batch_idx], y[batch_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64dfaaac-042e-46ce-8348-1838c05531bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# Parameter Initialization & Optimizer Setup\n",
    "# ---------------------\n",
    "\n",
    "rng = jax.random.PRNGKey(42)\n",
    "rng, rng1, rng2, rng3 = jax.random.split(rng, 4)\n",
    "# Initialize fc_in.\n",
    "_, params_fc_in = fc_in_init(rng1, (-1, 28*28))\n",
    "# Initialize ode_net.\n",
    "_, params_ode = ode_net_init(rng2, (-1, hidden_dim))\n",
    "# Initialize fc_out.\n",
    "_, params_fc_out = fc_out_init(rng3, (-1, hidden_dim))\n",
    "params = (params_fc_in, params_ode, params_fc_out)\n",
    "\n",
    "# Set up Adam optimizer.\n",
    "opt_init, opt_update, get_params = optimizers.adam(1e-3)\n",
    "opt_state = opt_init(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68c1b22a-08d9-4bec-9a58-77cc4322f13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3400, Train Acc: 94.89%, Test Acc: 94.78%\n",
      "Epoch 2, Loss: 0.1471, Train Acc: 96.04%, Test Acc: 95.39%\n",
      "Epoch 3, Loss: 0.1111, Train Acc: 96.66%, Test Acc: 95.91%\n",
      "Epoch 4, Loss: 0.0887, Train Acc: 97.63%, Test Acc: 96.60%\n",
      "Epoch 5, Loss: 0.0764, Train Acc: 98.06%, Test Acc: 96.74%\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "# Training Loop\n",
    "# ---------------------\n",
    "\n",
    "num_epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "@jax.jit\n",
    "def update(step, opt_state, x_batch, y_batch):\n",
    "    params = get_params(opt_state)\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(params, x_batch, y_batch)\n",
    "    opt_state = opt_update(step, grads, opt_state)\n",
    "    return opt_state, loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Use a new PRNG key per epoch for shuffling.\n",
    "    key = jax.random.PRNGKey(epoch)\n",
    "    batch_losses = []\n",
    "    for i, (x_batch, y_batch) in enumerate(get_batches(x_train, y_train, batch_size, key)):\n",
    "        opt_state, loss_val = update(i, opt_state, x_batch, y_batch)\n",
    "        batch_losses.append(loss_val)\n",
    "    params = get_params(opt_state)\n",
    "    train_loss = jnp.mean(jnp.array(batch_losses))\n",
    "    train_acc = accuracy_fn(params, x_train, y_train)\n",
    "    test_acc  = accuracy_fn(params, x_test, y_test)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}%, Test Acc: {test_acc*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
